{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPEW9kpL/o3YaNOy3Kp2qCO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vhnowf/machine-learning-course/blob/master/week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWaXT_o4h-H-"
      },
      "source": [
        "# load our dataset\n",
        "from sklearn.datasets import load_iris\n",
        "data = load_iris()\n",
        "X, Y = data['data'], data['target']"
      ],
      "execution_count": 363,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waaZtjuth_mP"
      },
      "source": [
        "# split our data into training and testing set with 90:10 ratio\n",
        "# use a fixed random state for reproducible results\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)\n",
        "\n"
      ],
      "execution_count": 364,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml_ye_HliDMm"
      },
      "source": [
        "# z-score normalization.\n",
        "# Remember to scale the training and test set separately to avoid data snooping.\n",
        "# We use the training set's mu and sigma for the test set.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n"
      ],
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn8an7ZciEYh"
      },
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "# Remember, no training is needed for KNN!\n",
        "def euclidean_distance(a,b):\n",
        "  return np.sqrt(np.sum((a-b)** 2))\n",
        "def evaluateKNN_single(k, x_train, y_train, data):\n",
        "    '''\n",
        "    Evaluate the classification for `data` with k-nearest neighbor\n",
        "    given training set (x_train, y_train).\n",
        "\n",
        "    Note that this function takes in one input instead of the whole\n",
        "    testing set.\n",
        "    \n",
        "    Input:\n",
        "        k      : hyperparameter for KNN\n",
        "        x_train: features of training set\n",
        "        y_train: labels of training set\n",
        "        data   : features of the data point to be evaluated\n",
        "    Output:\n",
        "        Classification of the input data point.\n",
        "    '''\n",
        "    distances = []\n",
        " \n",
        "    for i in range(x_train.shape[0]):\n",
        "         dist = euclidean_distance(data,x_train[i])\n",
        "         distances.append((dist, y_train[i]))\n",
        "    distances = sorted(distances)\n",
        "    votes = np.array(distances)[:k,1]\n",
        "    return int(Counter(votes).most_common(1)[0][0])\n",
        "\n",
        "  \n",
        "    \n"
      ],
      "execution_count": 366,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbF2JLFuSvS_"
      },
      "source": [
        "# Evaluation code for the whole dataset\n",
        "def evaluateKNN(k, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test):\n",
        "    correct = sum(map(lambda x: evaluateKNN_single(k, x_train, y_train, x[0]) == x[1], zip(x_test, y_test)))\n",
        "    print(f'Test accuracy with k={k}: {correct/len(y_test)*100:.4f}% ({correct}/{len(y_test)})')\n",
        "    # return the number of correct evaluations for us to check with the solution\n",
        "    return correct"
      ],
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i61jZdGPD4nt",
        "outputId": "98953022-64e9-4728-f2fd-23c75eaa8b65"
      },
      "source": [
        "label = evaluateKNN(2, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)\n",
        "print(label)"
      ],
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy with k=2: 93.3333% (14/15)\n",
            "14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovT3pUuK5d0n",
        "outputId": "f5065377-4bcb-4677-bdd1-375f2028b3ee"
      },
      "source": [
        "# and let's see how good is our model with k=5\n",
        "assert evaluateKNN(5) == len(y_test), \"Incorrect accuracy for 5-NN!\""
      ],
      "execution_count": 369,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy with k=5: 100.0000% (15/15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Lb4p_5s89ae",
        "outputId": "cccf720e-c2a1-4a1d-b3db-3ad62978682a"
      },
      "source": [
        "# and let's see how good is our model with k=5\n",
        "assert evaluateKNN(1) == len(y_test) - 1, \"Incorrect accuracy for 1 -NN!\""
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy with k=1: 93.3333% (14/15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4mrrdg1l1NI"
      },
      "source": [
        "def get_cluster_classification(x_data, centroids):\n",
        "    '''\n",
        "    A helper function that you will need later.\n",
        "    Classifies the points to their nearest cluster.\n",
        "    \n",
        "    Input:\n",
        "        x_data   : the data points\n",
        "        centroids: the cluster centroids\n",
        "    Output:\n",
        "        The centroid numbers that each data point belongs to (i.e. is nearest)\n",
        "    '''\n",
        "    \n",
        "    # IMPLEMENT HERE\n",
        "    clusters = np.array([np.argmin(np.linalg.norm(centroids- data_point, axis=1)) for data_point in x_data])\n",
        "    return clusters"
      ],
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VdIdfGgmBAQ"
      },
      "source": [
        "def kmeans(x_train, k, step, centroids = None):\n",
        "    '''\n",
        "    An implementation of K-means clustering.\n",
        "    \n",
        "    Input:\n",
        "        k      : number of clusters\n",
        "        x_train: training dataset\n",
        "        step   : number of recaliberation steps\n",
        "    Output:\n",
        "        The centroids of the clusters (a k x d matrix)\n",
        "    '''\n",
        "    \n",
        "    # IMPLEMENT HERE\n",
        "    if type(centroids) == type(None):\n",
        "      centroids = x_train[:k]\n",
        "    if centroids is None: centroids = x_train[:k]\n",
        "    for _ in range(step):\n",
        "      clusters = get_cluster_classification(x_train,centroids)\n",
        "      new_centroids = np.array([np.mean(x_train[clusters == i], axis = 0) for i in range(k)])\n",
        "      if np.allclose(new_centroids, centroids): break\n",
        "      centroids = new_centroids\n",
        "    return centroids\n"
      ],
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zg5suAb2mDKR"
      },
      "source": [
        "# we know that there are three classes\n",
        "centroids = kmeans(x_train, k=3, step=10)\n",
        "assert np.allclose(centroids, np.array([\n",
        "    [-1.02028733,  0.90854287, -1.32521428, -1.27540932],\n",
        "    [ 0.99363929,  0.01896468,  0.90355632,  0.92076921],\n",
        "    [-0.22539812, -1.02749927,  0.23322382,  0.15491878]\n",
        "])), \"Incorrect centroids for K-means!\""
      ],
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1EqH34jopLq"
      },
      "source": [
        "def kmeanspp(x_train, k, step):\n",
        "    '''\n",
        "    An implementation of K-means++ clustering.\n",
        "    \n",
        "    Input:\n",
        "        k      : number of clusters\n",
        "        x_train: training dataset\n",
        "        step   : number of recaliberation steps\n",
        "    Output:\n",
        "        The centroids of the clusters (a k x d matrix)\n",
        "    '''\n",
        "    # initialize the centroids according to the above criteria\n",
        "    \n",
        "    # IMPLEMENT HERE\n",
        "    init_centroid = [x_train[3]]\n",
        "    for _ in range(1,k):\n",
        "      init_centroid.append(x_train[np.argsort(np.linalg.norm(x_train-init_centroid[-1], axis = 1))[-4]])\n",
        "    centroids = np.array(init_centroid)\n",
        "\n",
        "    \n",
        "    # the rest should be identical to kmeans()\n",
        "    \n",
        "    # IMPLEMENT HERE\n",
        "    return kmeans(x_train, k, step, centroids)"
      ],
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3OSJF8YopG5"
      },
      "source": [
        "# now check if you did it correctly.\n",
        "centroidspp = kmeanspp(x_train, k=3, step=10)\n",
        "assert np.allclose(centroidspp, np.array([\n",
        "    [-0.0118057 , -0.87997489,  0.36942197,  0.30573876],\n",
        "    [ 1.15200055,  0.18878042,  0.98903982,  1.01136932],\n",
        "    [-1.03358934,  0.84835232, -1.32732076, -1.27380566]\n",
        "])), \"Incorrect centroids for K-means++!\"\n"
      ],
      "execution_count": 391,
      "outputs": []
    }
  ]
}