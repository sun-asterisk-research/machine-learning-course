{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: KNN & K-Means\n",
    "Again, fill the ellipses `...` with code, and don't remove `assert` lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use the Iris dataset again.\n",
    "Just goes to show that `sklearn` makes things way too easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our dataset\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X, Y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our data into training and testing set with 90:10 ratio\n",
    "# use a fixed random state for reproducible results\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score normalization.\n",
    "# Remember to scale the training and test set separately to avoid data snooping.\n",
    "# We use the training set's mu and sigma for the test set.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN: $k$-Nearest Neighbors\n",
    "Evaluate the test set with data from the training set.\n",
    "\n",
    "In case of ties, pick the smallest class (i.e. we prefer class 0 to class 1 to class 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "import operator\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "def hakaru_distance(input1, input2):\n",
    "    # input1 cố định: input2^2 - 2*input1*input2\n",
    "    res = np.array(input2).dot(input2) - 2*np.array(input1).dot(input2)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def weight(distance):\n",
    "    res = np.exp(-distance)\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember, no training is needed for KNN!\n",
    "def evaluateKNN_single(k, x_train, y_train, data):\n",
    "    '''\n",
    "    Evaluate the classification for `data` with k-nearest neighbor\n",
    "    given training set (x_train, y_train).\n",
    "\n",
    "    Note that this function takes in one input instead of the whole\n",
    "    testing set.\n",
    "\n",
    "    Input:\n",
    "        k      : hyperparameter for KNN\n",
    "        x_train: features of training set\n",
    "        y_train: labels of training set\n",
    "        data   : features of the data point to be evaluated\n",
    "    Output:\n",
    "        Classification of the input data point.\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    distance = []\n",
    "    for i in range(len(x_train)):\n",
    "        distance.append([hakaru_distance(data, x_train[i]), y_train[i]])\n",
    "    distance.sort(key=lambda x:x[0])\n",
    "    distance = distance[:k]\n",
    "\n",
    "    mydict = {}\n",
    "    dis_1 = np.array(data).dot(data)\n",
    "    for i in range(k):\n",
    "        if distance[i][1] not in mydict:\n",
    "            mydict[distance[i][1]] = 0\n",
    "        mydict[distance[i][1]] += weight(distance[i][0] + dis_1)\n",
    "    return max(mydict, key=mydict.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation code for the whole dataset\n",
    "def evaluateKNN(k, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test):\n",
    "    correct = sum(map(lambda x: evaluateKNN_single(k, x_train, y_train, x[0]) == x[1], zip(x_test, y_test)))\n",
    "    print(f'Test accuracy with k={k}: {correct/len(y_test)*100:.4f}% ({correct}/{len(y_test)})')\n",
    "    # return the number of correct evaluations for us to check with the solution\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with k=5: 100.0000% (15/15)\n"
     ]
    }
   ],
   "source": [
    "# and let's see how good is our model with k=5\n",
    "assert evaluateKNN(5) == len(y_test), \"Incorrect accuracy for 5-NN!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with k=1: 93.3333% (14/15)\n"
     ]
    }
   ],
   "source": [
    "# What if we use 1-NN?\n",
    "assert evaluateKNN(1) == len(y_test) - 1, \"Incorrect accuracy for 1-NN!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering\n",
    "Use the first 3 data points as initial cluster centroids (medoids anyone?)\n",
    "\n",
    "Run the recaliberation step 10 times. Yes, it converges that quickly for a NP-hard problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_classification(x_data, centroids):\n",
    "    '''\n",
    "    A helper function that you will need later.\n",
    "    Classifies the points to their nearest cluster.\n",
    "    \n",
    "    Input:\n",
    "        x_data   : the data points\n",
    "        centroids: the cluster centroids\n",
    "    Output:\n",
    "        The centroid numbers that each data point belongs to (i.e. is nearest)\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    distance = []\n",
    "    for i in range(len(centroids)):\n",
    "        distance.append([hakaru_distance(x_data, centroids[i]), i])\n",
    "\n",
    "    distance.sort(key=lambda x:x[0])\n",
    "    return distance[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "import random"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(x_train, k, step):\n",
    "    '''\n",
    "    An implementation of K-means clustering.\n",
    "    \n",
    "    Input:\n",
    "        k      : number of clusters\n",
    "        x_train: training dataset\n",
    "        step   : number of recaliberation steps\n",
    "    Output:\n",
    "        The centroids of the clusters (a k x d matrix)\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "\n",
    "    centroids = np.array(x_train[:3])\n",
    "\n",
    "    for i in range(step):\n",
    "        my_list = []\n",
    "\n",
    "        for j in range(k):\n",
    "            my_list.append([])\n",
    "\n",
    "        for j in x_train:\n",
    "            my_list[get_cluster_classification(j, centroids)].append(j)\n",
    "\n",
    "        for j in range(k):\n",
    "            centroids[j] = sum(my_list[j])/len(my_list[j])\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we know that there are three classes\n",
    "centroids = kmeans(x_train, k=3, step=10)\n",
    "assert np.allclose(centroids, np.array([\n",
    "    [-1.02028733,  0.90854287, -1.32521428, -1.27540932],\n",
    "    [ 0.99363929,  0.01896468,  0.90355632,  0.92076921],\n",
    "    [-0.22539812, -1.02749927,  0.23322382,  0.15491878]\n",
    "])), \"Incorrect centroids for K-means!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means++\n",
    "Use the 4th data point as the intial centroid each step ([chosen with randomness](https://xkcd.com/221/)):\n",
    "- The first initial centroid should be the 4th data point.\n",
    "- The next initial centroids should be the 4th furthest data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeanspp(x_train, k, step):\n",
    "    '''\n",
    "    An implementation of K-means++ clustering.\n",
    "    \n",
    "    Input:\n",
    "        k      : number of clusters\n",
    "        x_train: training dataset\n",
    "        step   : number of recaliberation steps\n",
    "    Output:\n",
    "        The centroids of the clusters (a k x d matrix)\n",
    "    '''\n",
    "    # initialize the centroids according to the above criteria\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    centroids = []\n",
    "    centroids.append(x_train[4])\n",
    "    for i in range(k, 1, -1):\n",
    "        centroids.append(x_train[i*4])\n",
    "    centroids = np.array(centroids)\n",
    "    # the rest should be identical to kmeans()\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "\n",
    "\n",
    "    for i in range(step):\n",
    "        my_list = []\n",
    "\n",
    "        for j in range(k):\n",
    "            my_list.append([])\n",
    "\n",
    "        for j in x_train:\n",
    "            my_list[get_cluster_classification(j, centroids)].append(j)\n",
    "\n",
    "        for j in range(k):\n",
    "            centroids[j] = sum(my_list[j])/len(my_list[j])\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check if you did it correctly.\n",
    "centroidspp = kmeanspp(x_train, k=3, step=10)\n",
    "assert np.allclose(centroidspp, np.array([\n",
    "    [-0.0118057 , -0.87997489,  0.36942197,  0.30573876],\n",
    "    [ 1.15200055,  0.18878042,  0.98903982,  1.01136932],\n",
    "    [-1.03358934,  0.84835232, -1.32732076, -1.27380566]\n",
    "\n",
    "\n",
    "])), \"Incorrect centroids for K-means++!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Classification using clustering\n",
    "We can treat each cluster to be of a different class, and the class with most points in each cluster is the classification for that cluster. Think voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the associated classification for each cluster\n",
    "def get_cluster_label(centroids, x_train, y_train):\n",
    "    '''\n",
    "    Get the classification for each cluster using training set.\n",
    "    \n",
    "    Input:\n",
    "        centroids: the centroids of the clusters\n",
    "        x_train  : features of training set\n",
    "        y_train  : labels of training set\n",
    "    Output:\n",
    "        The classifications for the clusters.\n",
    "    '''\n",
    "    # remember to return a numpy array instead of a Python list!\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    my_list = []\n",
    "\n",
    "    for i in range(len(centroids)):\n",
    "        my_list.append({})\n",
    "        for j in range(max(y_train) + 1):\n",
    "            my_list[i][j] = 0\n",
    "\n",
    "    for i in range(len(x_train)):\n",
    "        my_list[get_cluster_classification(x_train[i], centroids)][y_train[i]] += 1\n",
    "\n",
    "    res = []\n",
    "    for i in my_list:\n",
    "        res.append(max(i, key=i.get))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "labels = get_cluster_label(centroids, x_train, y_train)\n",
    "labelspp = get_cluster_label(centroidspp, x_train, y_train)\n",
    "# each cluster nicely belongs to a different class\n",
    "assert (labels == [0, 2, 1]).all(), \"Incorrect K-means cluster label(s)!\"\n",
    "assert (labelspp == [1, 2, 0]).all(), \"Incorrect K-means++ cluster label(s)!\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kmeans_classification(centroids, labels, x_data):\n",
    "    '''\n",
    "    Get the classification for each data point using centroid labels.\n",
    "    \n",
    "    Input:\n",
    "        centroids: the centroids of the clusters\n",
    "        labels   : the labels for the clusters\n",
    "        x_data   : the data to be classified\n",
    "    Output:\n",
    "        The classifications for the data.\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    res = []\n",
    "\n",
    "    for i in x_data:\n",
    "        res.append(labels[get_cluster_classification(i, centroids)])\n",
    "\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the classifications\n",
    "y_train_pred = evaluate_kmeans_classification(centroids, labels, x_train)\n",
    "y_test_pred = evaluate_kmeans_classification(centroids, labels, x_test)\n",
    "y_train_pred_pp = evaluate_kmeans_classification(centroidspp, labelspp, x_train)\n",
    "y_test_pred_pp = evaluate_kmeans_classification(centroidspp, labelspp, x_test)\n",
    "\n",
    "# and check for correctness\n",
    "assert (y_train_pred == [2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 2, 1, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 2, 0, 2, 0, 0, 2, 1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 2, 1, 2, 1, 1, 2, 1, 2, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 2, 1, 2, 0, 1, 1, 0, 1, 2]).all()\n",
    "assert (y_test_pred == [1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0]).all()\n",
    "assert (y_train_pred_pp == [2, 2, 1, 1, 2, 0, 1, 0, 2, 2, 2, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0, 2, 1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 1, 2, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2]).all()\n",
    "assert (y_test_pred_pp == [1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] For K-means:\n",
      "Training accuracy: 82.9630% (112/135)\n",
      "Training accuracy: 93.3333% (14/15)\n",
      "[+] For K-means++:\n",
      "Training accuracy: 80.0000% (108/135)\n",
      "Training accuracy: 93.3333% (14/15)\n"
     ]
    }
   ],
   "source": [
    "# evaluate prediction accuracy\n",
    "print('[+] For K-means:')\n",
    "train_score = np.sum(y_train_pred == y_train)\n",
    "print(f'Training accuracy: {train_score / len(y_train) * 100:.4f}% ({train_score}/{len(y_train)})')\n",
    "train_score = np.sum(y_test_pred == y_test)\n",
    "print(f'Training accuracy: {train_score / len(y_test) * 100:.4f}% ({train_score}/{len(y_test)})')\n",
    "print('[+] For K-means++:')\n",
    "train_score = np.sum(y_train_pred_pp == y_train)\n",
    "print(f'Training accuracy: {train_score / len(y_train) * 100:.4f}% ({train_score}/{len(y_train)})')\n",
    "train_score = np.sum(y_test_pred_pp == y_test)\n",
    "print(f'Training accuracy: {train_score / len(y_test) * 100:.4f}% ({train_score}/{len(y_test)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 720x720 with 4 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# and plot out confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "fig = plt.subplot(2, 2, 1)\n",
    "sn.heatmap(confusion_matrix(y_train, y_train_pred), annot=True, cbar=False, square=True, linewidths=0.5)\n",
    "fig.set_title('K-means, train set')\n",
    "\n",
    "fig = plt.subplot(2, 2, 2)\n",
    "sn.heatmap(confusion_matrix(y_test, y_test_pred), annot=True, cbar=False, square=True, linewidths=0.5)\n",
    "fig.set_title('K-means, test set')\n",
    "\n",
    "fig = plt.subplot(2, 2, 3)\n",
    "sn.heatmap(confusion_matrix(y_train, y_train_pred_pp), annot=True, cbar=False, square=True, linewidths=0.5)\n",
    "fig.set_title('K-means++, train set')\n",
    "\n",
    "fig = plt.subplot(2, 2, 4)\n",
    "sn.heatmap(confusion_matrix(y_test, y_test_pred_pp), annot=True, cbar=False, square=True, linewidths=0.5)\n",
    "fig.set_title('K-means++, test set');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}