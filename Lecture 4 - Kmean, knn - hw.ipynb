{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4: KNN & K-Means\n",
    "Again, fill the ellipses `...` with code, and don't remove `assert` lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will use the Iris dataset again.\n",
    "Just goes to show that `sklearn` makes things way too easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our dataset\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X, Y = data['data'], data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split our data into training and testing set with 90:10 ratio\n",
    "# use a fixed random state for reproducible results\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score normalization.\n",
    "# Remember to scale the training and test set separately to avoid data snooping.\n",
    "# We use the training set's mu and sigma for the test set.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN: $k$-Nearest Neighbors\n",
    "Evaluate the test set with data from the training set.\n",
    "\n",
    "In case of ties, pick the smallest class (i.e. we prefer class 0 to class 1 to class 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Remember, no training is needed for KNN!\n",
    "def evaluateKNN_single(k, x_train, y_train, data):\n",
    "    '''\n",
    "    Evaluate the classification for `data` with k-nearest neighbor\n",
    "    given training set (x_train, y_train).\n",
    "\n",
    "    Note that this function takes in one input instead of the whole\n",
    "    testing set.\n",
    "    \n",
    "    Input:\n",
    "        k      : hyperparameter for KNN\n",
    "        x_train: features of training set\n",
    "        y_train: labels of training set\n",
    "        data   : features of the data point to be evaluated\n",
    "    Output:\n",
    "        Classification of the input data point.\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    tops = []\n",
    "    votes = []\n",
    "    class_input = []\n",
    "    for i in range(len(x_train)):\n",
    "        distance = np.linalg.norm(x_train[i] - data)\n",
    "        tops.append([distance, i])\n",
    "    tops.sort()\n",
    "    tops = tops[:k]\n",
    "    for top, i in tops:\n",
    "        votes.append(y_train[i])\n",
    "    return min(votes)\n",
    "for i in range(14):\n",
    "    evaluateKNN_single(5, x_train, y_train, x_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation code for the whole dataset\n",
    "def evaluateKNN(k, x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test):\n",
    "    correct = sum(map(lambda x: evaluateKNN_single(k, x_train, y_train, x[0]) == x[1], zip(x_test, y_test)))\n",
    "    print(f'Test accuracy with k={k}: {correct/len(y_test)*100:.4f}% ({correct}/{len(y_test)})')\n",
    "    # return the number of correct evaluations for us to check with the solution\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with k=5: 100.0000% (15/15)\n"
     ]
    }
   ],
   "source": [
    "# and let's see how good is our model with k=5\n",
    "assert evaluateKNN(5) == len(y_test), \"Incorrect accuracy for 5-NN!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy with k=1: 93.3333% (14/15)\n"
     ]
    }
   ],
   "source": [
    "# What if we use 1-NN?\n",
    "assert evaluateKNN(1) == len(y_test) - 1, \"Incorrect accuracy for 1-NN!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means clustering\n",
    "Use the first 3 data points as initial cluster centroids (medoids anyone?)\n",
    "\n",
    "Run the recaliberation step 10 times. Yes, it converges that quickly for a NP-hard problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def is_converged(clusters, new_clusters):   #check xem có nếu không có sự thay đổi tâm\n",
    "    return all(sorted(i) == sorted(j) for i, j in zip(clusters, new_clusters))\n",
    "\n",
    "def get_cluster_classification(x_data, centroids):\n",
    "    '''\n",
    "    A helper function that you will need later.\n",
    "    Classifies the points to their nearest cluster.\n",
    "    \n",
    "    Input:\n",
    "        x_data   : the data points\n",
    "        centroids: the cluster centroids\n",
    "    Output:\n",
    "        The centroid numbers that each data point belongs to (i.e. is nearest)\n",
    "        Tâm của các điểm dữ liệu\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    clusters = []\n",
    "    K = len(centroids)\n",
    "    for i in range(K):\n",
    "        clusters.append([])\n",
    "    for sample_index, sample in enumerate(x_data):  \n",
    "        \n",
    "        min_dist = np.inf\n",
    "        min_index = 0\n",
    "        for centroid_index, centroid in enumerate(centroids):\n",
    "            dist = np.linalg.norm(sample - centroid)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                min_index = centroid_index\n",
    "                \n",
    "        clusters[min_index].append(sample_index)\n",
    "    \n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(x_train, k, step):\n",
    "    '''\n",
    "    An implementation of K-means clustering.\n",
    "    \n",
    "    Input:\n",
    "        k      : number of clusters\n",
    "        x_train: training dataset\n",
    "        step   : number of recaliberation steps\n",
    "    Output:\n",
    "        The centroids of the clusters (a k x d matrix)\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    \n",
    "    random_index = random.sample(range(x_train.shape[1]), k)\n",
    "    centroids = x_train[random_index]\n",
    "    new_clusters = None\n",
    "    for i in range(step):\n",
    "        clusters = get_cluster_classification(x_train, centroids)\n",
    "        \n",
    "        new_centroids = []\n",
    "        for cluster in clusters:\n",
    "            new_centroids.append(x_train[cluster].mean(axis=0).tolist())\n",
    "        \n",
    "        if new_clusters is not None and is_converged(clusters, new_clusters): \n",
    "            break      \n",
    "        centroids = new_centroids\n",
    "        new_clusters = clusters\n",
    "        \n",
    "    return np.array(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.02028733  0.90854287 -1.32521428 -1.27540932]\n",
      " [ 0.99363929  0.01896468  0.90355632  0.92076921]\n",
      " [-0.22539812 -1.02749927  0.23322382  0.15491878]]\n"
     ]
    }
   ],
   "source": [
    "# we know that there are three classes\n",
    "centroids = kmeans(x_train, k=3, step=10)\n",
    "print(centroids)\n",
    "assert np.allclose(centroids, np.array([\n",
    "    [-1.02028733,  0.90854287, -1.32521428, -1.27540932],\n",
    "    [ 0.99363929,  0.01896468,  0.90355632,  0.92076921],\n",
    "    [-0.22539812, -1.02749927,  0.23322382,  0.15491878]\n",
    "])), \"Incorrect centroids for K-means!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-means++\n",
    "Use the 4th data point as the intial centroid each step ([chosen with randomness](https://xkcd.com/221/)):\n",
    "- The first initial centroid should be the 4th data point.\n",
    "- The next initial centroids should be the 4th furthest data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def kmeanspp(x_train, k, step):\n",
    "    '''\n",
    "    An implementation of K-means++ clustering.\n",
    "    \n",
    "    Input:\n",
    "        k      : number of clusters\n",
    "        x_train: training dataset\n",
    "        step   : number of recaliberation steps\n",
    "    Output:\n",
    "        The centroids of the clusters (a k x d matrix)\n",
    "    '''\n",
    "    # initialize the centroids according to the above criteria\n",
    "    # IMPLEMENT HERE\n",
    "    \n",
    "    centroids = []\n",
    "    centroids.append(x_train[3])\n",
    "    \n",
    "    ## compute remaining k - 1 centroids \n",
    "    for i in range(k-1):\n",
    "        dist_max = {}\n",
    "        for x_index, x in enumerate(x_train):\n",
    "            dist = []\n",
    "            for centroid in centroids:\n",
    "                dist.append(np.linalg.norm(x - centroid))\n",
    "            dist.sort(reverse=True)\n",
    "            dist_max[x_index] = dist[0]\n",
    "        dist_max = sorted(dist_max.items(), key=lambda x: x[1], reverse=True)\n",
    "        dem = 0\n",
    "        for j in dist_max:\n",
    "            if dem == 3:\n",
    "                centroids.append(x_train[j[0]])\n",
    "                break\n",
    "            else: \n",
    "                dem += 1\n",
    "    # the rest should be identical to kmeans() \n",
    "    # IMPLEMENT HERE\n",
    "    for i in range(step):\n",
    "        clusters = get_cluster_classification(x_train, centroids)       \n",
    "        new_centroids = []\n",
    "        for cluster in clusters:\n",
    "            new_centroids.append(x_train[cluster].mean(axis=0).tolist())\n",
    "        centroids = new_centroids\n",
    "        \n",
    "    return np.array(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0118057  -0.87997489  0.36942197  0.30573876]\n",
      " [ 1.15200055  0.18878042  0.98903982  1.01136932]\n",
      " [-1.03358934  0.84835232 -1.32732076 -1.27380566]]\n"
     ]
    }
   ],
   "source": [
    "# now check if you did it correctly.\n",
    "centroidspp = kmeanspp(x_train, k=3, step=10)\n",
    "print(centroidspp)\n",
    "assert np.allclose(centroidspp, np.array([\n",
    "    [-0.0118057 , -0.87997489,  0.36942197,  0.30573876],\n",
    "    [ 1.15200055,  0.18878042,  0.98903982,  1.01136932],\n",
    "    [-1.03358934,  0.84835232, -1.32732076, -1.27380566]\n",
    "])), \"Incorrect centroids for K-means++!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Classification using clustering\n",
    "We can treat each cluster to be of a different class, and the class with most points in each cluster is the classification for that cluster. Think voting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the associated classification for each cluster\n",
    "def get_cluster_label(centroids, x_train, y_train):\n",
    "    '''\n",
    "    Get the classification for each cluster using training set.\n",
    "    \n",
    "    Input:\n",
    "        centroids: the centroids of the clusters\n",
    "        x_train  : features of training set\n",
    "        y_train  : labels of training set\n",
    "    Output:\n",
    "        The classifications for the clusters.\n",
    "    '''\n",
    "    # remember to return a numpy array instead of a Python list!\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    labels = []\n",
    "    for centroid in centroids:\n",
    "        labels.append(evaluateKNN_single(1, x_train, y_train, centroid))\n",
    "    return np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = get_cluster_label(centroids, x_train, y_train)\n",
    "labelspp = get_cluster_label(centroidspp, x_train, y_train)\n",
    "# each cluster nicely belongs to a different class\n",
    "assert (labels == [0, 2, 1]).all(), \"Incorrect K-means cluster label(s)!\"\n",
    "assert (labelspp == [1, 2, 0]).all(), \"Incorrect K-means++ cluster label(s)!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_kmeans_classification(centroids, labels, x_data):\n",
    "    '''\n",
    "    Get the classification for each data point using centroid labels.\n",
    "    \n",
    "    Input:\n",
    "        centroids: the centroids of the clusters\n",
    "        labels   : the labels for the clusters\n",
    "        x_data   : the data to be classified\n",
    "    Output:\n",
    "        The classifications for the data.\n",
    "    '''\n",
    "    \n",
    "    # IMPLEMENT HERE\n",
    "    y_pred = []\n",
    "    for x in x_data:\n",
    "        dist_min = np.inf\n",
    "        label = 0\n",
    "        for cen_index, cen in enumerate(centroids):\n",
    "            dist = np.linalg.norm(x - cen)\n",
    "            if dist < dist_min:\n",
    "                label = labels[cen_index]\n",
    "                dist_min = dist\n",
    "        y_pred.append(label)\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the classifications\n",
    "y_train_pred = evaluate_kmeans_classification(centroids, labels, x_train)\n",
    "y_test_pred = evaluate_kmeans_classification(centroids, labels, x_test)\n",
    "y_train_pred_pp = evaluate_kmeans_classification(centroidspp, labelspp, x_train)\n",
    "y_test_pred_pp = evaluate_kmeans_classification(centroidspp, labelspp, x_test)\n",
    "\n",
    "# and check for correctness\n",
    "assert (y_train_pred == [2, 2, 1, 1, 2, 0, 2, 0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 1, 2, 2, 2, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 2, 1, 1, 1, 2, 1, 0, 1, 2, 0, 0, 1, 2, 0, 2, 0, 0, 2, 1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 2, 2, 2, 2, 0, 2, 1, 2, 1, 1, 2, 1, 2, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 2, 1, 2, 0, 1, 1, 0, 1, 2]).all()\n",
    "assert (y_test_pred == [1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0]).all()\n",
    "assert (y_train_pred_pp == [2, 2, 1, 1, 2, 0, 1, 0, 2, 2, 2, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 1, 1, 2, 2, 2, 1, 2, 1, 0, 2, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 2, 0, 1, 1, 0, 1, 1, 1, 1, 2, 1, 0, 1, 1, 0, 0, 1, 2, 0, 1, 0, 0, 2, 1, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 2, 2, 0, 1, 1, 1, 2, 2, 0, 2, 1, 2, 1, 1, 1, 0, 1, 1, 0, 1, 2, 2, 0, 1, 2, 2, 0, 2, 0, 2, 2, 2, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 1, 2]).all()\n",
    "assert (y_test_pred_pp == [1, 0, 2, 1, 2, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0]).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] For K-means:\n",
      "Training accuracy: 82.9630% (112/135)\n",
      "Training accuracy: 93.3333% (14/15)\n",
      "[+] For K-means++:\n",
      "Training accuracy: 80.0000% (108/135)\n",
      "Training accuracy: 93.3333% (14/15)\n"
     ]
    }
   ],
   "source": [
    "# evaluate prediction accuracy\n",
    "print('[+] For K-means:')\n",
    "train_score = np.sum(y_train_pred == y_train)\n",
    "print(f'Training accuracy: {train_score / len(y_train) * 100:.4f}% ({train_score}/{len(y_train)})')\n",
    "train_score = np.sum(y_test_pred == y_test)\n",
    "print(f'Training accuracy: {train_score / len(y_test) * 100:.4f}% ({train_score}/{len(y_test)})')\n",
    "print('[+] For K-means++:')\n",
    "train_score = np.sum(y_train_pred_pp == y_train)\n",
    "print(f'Training accuracy: {train_score / len(y_train) * 100:.4f}% ({train_score}/{len(y_train)})')\n",
    "train_score = np.sum(y_test_pred_pp == y_test)\n",
    "print(f'Training accuracy: {train_score / len(y_test) * 100:.4f}% ({train_score}/{len(y_test)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# and plot out confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "fig = plt.subplot(2, 2, 1)\n",
    "sn.heatmap(confusion_matrix(y_train, y_train_pred), annot=True, cbar=False, square=True, linewidths=0.5)\n",
    "fig.set_title('K-means, train set')\n",
    "\n",
    "fig = plt.subplot(2, 2, 2)\n",
    "sn.heatmap(confusion_matrix(y_test, y_test_pred), annot=True, cbar=False, square=True, linewidths=0.5)\n",
    "fig.set_title('K-means, test set')\n",
    "\n",
    "fig = plt.subplot(2, 2, 3)\n",
    "sn.heatmap(confusion_matrix(y_train, y_train_pred_pp), annot=True, cbar=False, square=True, linewidths=0.5)\n",
    "fig.set_title('K-means++, train set')\n",
    "\n",
    "fig = plt.subplot(2, 2, 4)\n",
    "sn.heatmap(confusion_matrix(y_test, y_test_pred_pp), annot=True, cbar=False, square=True, linewidths=0.5)\n",
    "fig.set_title('K-means++, test set');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
