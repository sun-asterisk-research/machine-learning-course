{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Logistics Regression\n",
    "Implement everywhere that has an ellipsis (`...`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X, Y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only classify class 1 vs. class 2\n",
    "\n",
    "X = X[:, :]\n",
    "idx = (Y!=0)\n",
    "X = X[idx, :]\n",
    "Y = Y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization\n",
    "Remember: normalization is done per feature, not all at once. Also, remember that Y is [1, 2] instead of [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Don't forget the bias!\n",
    "X = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "Y = (Y - np.min(Y)) / (np.max(Y) - np.min(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define classification model\n",
    "Create parameters here. Initialize with zeros. In case you forgot: $Y = \\sigma(X\\Theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward Propagation:**\n",
    "$$Z = Xw + b$$\n",
    "$$\\hat{y} = \\sigma(Z) =\\sigma(Xw + b) $$\n",
    "$$J(w, b) = -\\frac{1}{m}\\sum_{i=1}^m{ \\Big( y^{(i)} log( \\hat{y}^{(i)}) + (1-y^{(i)}) log(1 - \\hat{y}^{(i)}) \\Big)} \\tag{5}$$\n",
    "\n",
    "**and Backward**\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X^T(\\hat{y}-y)\\tag{6}$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}^{(i)}-y^{(i)})\\tag{7}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize params\n",
    "def initialize_params(X):\n",
    "    '''Initialize w, b with zeros and return'''\n",
    "    w = np.zeros((X.shape[1], 1))\n",
    "    b = np.zeros((1, 1))\n",
    "    return w, b\n",
    "# Implement sigmoid\n",
    "def sigmoid(Z):\n",
    "    return 1/(1 + np.exp(-Z))\n",
    "# Forward propagation\n",
    "def forward(w, b, X):\n",
    "    '''Return y_hat'''\n",
    "    Z = np.dot(X, w) + b\n",
    "    y_hat = sigmoid(Z)\n",
    "    return y_hat\n",
    "# Binary cross entropy loss\n",
    "def binany_cross_entropy(y, y_hat):\n",
    "    '''Calculate loss function J and return'''\n",
    "    J = -np.mean(y*np.log(y_hat) + (1-y)*np.log(1-y_hat))\n",
    "    return J\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward propagation\n",
    "def backward(X, y, y_hat, w, b):\n",
    "    '''Calculate dw, db and return'''\n",
    "    m = X.shape[0]\n",
    "    dw = (1/m) * np.dot(X.T, (y_hat - y))\n",
    "    db = (1/m) * np.sum(y_hat - y, keepdims=True)\n",
    "    return dw, db\n",
    "\n",
    "# Update parameters\n",
    "def update_params(w, b, dw, db, learning_rate):\n",
    "    '''Update w, b and return'''\n",
    "    w = w - learning_rate * dw\n",
    "    b = b - learning_rate * db\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    '''Return predicted y of X'''\n",
    "    y_hat = forward(w, b, X)\n",
    "    return y_hat > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, Y, w,b):\n",
    "    '''\n",
    "    Evaluate the model, represented by `weight`, with data (X, Y).\n",
    "    \n",
    "    Input:\n",
    "        X:      data features\n",
    "        Y:      data labels\n",
    "        weight: model weights\n",
    "    Ouput:\n",
    "        Model accuracy on input data.\n",
    "    '''\n",
    "    # implement your code here\n",
    "    y_hat = predict(w, b, X)\n",
    "    count_ = 0\n",
    "    for i in range(X.shape[1]):\n",
    "        if Y[i] == y_hat[i]:\n",
    "            count += 1\n",
    "    return count_ / X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "alpha = 1e-2\n",
    "# epochs\n",
    "epoch = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3])\n",
    "b = np.array([1,2,3])\n",
    "np.linalg.norm(a-b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process\n",
    "def train(X, y, iterations, learning_rate):\n",
    "    '''Train w, b and return'''\n",
    "    w, b = initialize_params(X)\n",
    "    for i in range(iterations):\n",
    "        y_hat = forward(w, b, X)\n",
    "        J = binany_cross_entropy(y, y_hat)\n",
    "        dw, db = backward(X, y, y_hat, w, b)\n",
    "        w, b = update_params(w, b, dw, db, learning_rate)\n",
    "        \n",
    "    return w, b\n",
    "w, b = train(X,Y,1000,1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.04878128, -0.04878128, -0.04878128, -0.04878128, -0.04878128,\n",
       "        -0.04878128, -0.04878128, -0.04878128, -0.04878128, -0.04878128,\n",
       "        -0.04878128, -0.04878128, -0.04878128, -0.04878128, -0.04878128,\n",
       "        -0.04878128, -0.04878128, -0.04878128, -0.04878128, -0.04878128,\n",
       "        -0.04878128, -0.04878128, -0.04878128, -0.04878128, -0.04878128,\n",
       "        -0.04878128, -0.04878128, -0.04878128, -0.04878128, -0.04878128,\n",
       "        -0.04878128, -0.04878128, -0.04878128, -0.04878128, -0.04878128,\n",
       "        -0.04878128, -0.04878128, -0.04878128, -0.04878128, -0.04878128,\n",
       "        -0.04878128, -0.04878128, -0.04878128, -0.04878128, -0.04878128,\n",
       "        -0.04878128, -0.04878128, -0.04878128, -0.04878128, -0.04878128,\n",
       "         0.04878128,  0.04878128,  0.04878128,  0.04878128,  0.04878128,\n",
       "         0.04878128,  0.04878128,  0.04878128,  0.04878128,  0.04878128,\n",
       "         0.04878128,  0.04878128,  0.04878128,  0.04878128,  0.04878128,\n",
       "         0.04878128,  0.04878128,  0.04878128,  0.04878128,  0.04878128,\n",
       "         0.04878128,  0.04878128,  0.04878128,  0.04878128,  0.04878128,\n",
       "         0.04878128,  0.04878128,  0.04878128,  0.04878128,  0.04878128,\n",
       "         0.04878128,  0.04878128,  0.04878128,  0.04878128,  0.04878128,\n",
       "         0.04878128,  0.04878128,  0.04878128,  0.04878128,  0.04878128,\n",
       "         0.04878128,  0.04878128,  0.04878128,  0.04878128,  0.04878128,\n",
       "         0.04878128,  0.04878128,  0.04878128,  0.04878128,  0.04878128],\n",
       "       [-0.03719285, -0.03719285, -0.03719285, -0.03719285, -0.03719285,\n",
       "        -0.03719285, -0.03719285, -0.03719285, -0.03719285, -0.03719285,\n",
       "        -0.03719285, -0.03719285, -0.03719285, -0.03719285, -0.03719285,\n",
       "        -0.03719285, -0.03719285, -0.03719285, -0.03719285, -0.03719285,\n",
       "        -0.03719285, -0.03719285, -0.03719285, -0.03719285, -0.03719285,\n",
       "        -0.03719285, -0.03719285, -0.03719285, -0.03719285, -0.03719285,\n",
       "        -0.03719285, -0.03719285, -0.03719285, -0.03719285, -0.03719285,\n",
       "        -0.03719285, -0.03719285, -0.03719285, -0.03719285, -0.03719285,\n",
       "        -0.03719285, -0.03719285, -0.03719285, -0.03719285, -0.03719285,\n",
       "        -0.03719285, -0.03719285, -0.03719285, -0.03719285, -0.03719285,\n",
       "         0.03719285,  0.03719285,  0.03719285,  0.03719285,  0.03719285,\n",
       "         0.03719285,  0.03719285,  0.03719285,  0.03719285,  0.03719285,\n",
       "         0.03719285,  0.03719285,  0.03719285,  0.03719285,  0.03719285,\n",
       "         0.03719285,  0.03719285,  0.03719285,  0.03719285,  0.03719285,\n",
       "         0.03719285,  0.03719285,  0.03719285,  0.03719285,  0.03719285,\n",
       "         0.03719285,  0.03719285,  0.03719285,  0.03719285,  0.03719285,\n",
       "         0.03719285,  0.03719285,  0.03719285,  0.03719285,  0.03719285,\n",
       "         0.03719285,  0.03719285,  0.03719285,  0.03719285,  0.03719285,\n",
       "         0.03719285,  0.03719285,  0.03719285,  0.03719285,  0.03719285,\n",
       "         0.03719285,  0.03719285,  0.03719285,  0.03719285,  0.03719285],\n",
       "       [-0.01323187, -0.01323187, -0.01323187, -0.01323187, -0.01323187,\n",
       "        -0.01323187, -0.01323187, -0.01323187, -0.01323187, -0.01323187,\n",
       "        -0.01323187, -0.01323187, -0.01323187, -0.01323187, -0.01323187,\n",
       "        -0.01323187, -0.01323187, -0.01323187, -0.01323187, -0.01323187,\n",
       "        -0.01323187, -0.01323187, -0.01323187, -0.01323187, -0.01323187,\n",
       "        -0.01323187, -0.01323187, -0.01323187, -0.01323187, -0.01323187,\n",
       "        -0.01323187, -0.01323187, -0.01323187, -0.01323187, -0.01323187,\n",
       "        -0.01323187, -0.01323187, -0.01323187, -0.01323187, -0.01323187,\n",
       "        -0.01323187, -0.01323187, -0.01323187, -0.01323187, -0.01323187,\n",
       "        -0.01323187, -0.01323187, -0.01323187, -0.01323187, -0.01323187,\n",
       "         0.01323187,  0.01323187,  0.01323187,  0.01323187,  0.01323187,\n",
       "         0.01323187,  0.01323187,  0.01323187,  0.01323187,  0.01323187,\n",
       "         0.01323187,  0.01323187,  0.01323187,  0.01323187,  0.01323187,\n",
       "         0.01323187,  0.01323187,  0.01323187,  0.01323187,  0.01323187,\n",
       "         0.01323187,  0.01323187,  0.01323187,  0.01323187,  0.01323187,\n",
       "         0.01323187,  0.01323187,  0.01323187,  0.01323187,  0.01323187,\n",
       "         0.01323187,  0.01323187,  0.01323187,  0.01323187,  0.01323187,\n",
       "         0.01323187,  0.01323187,  0.01323187,  0.01323187,  0.01323187,\n",
       "         0.01323187,  0.01323187,  0.01323187,  0.01323187,  0.01323187,\n",
       "         0.01323187,  0.01323187,  0.01323187,  0.01323187,  0.01323187],\n",
       "       [-0.02760426, -0.02760426, -0.02760426, -0.02760426, -0.02760426,\n",
       "        -0.02760426, -0.02760426, -0.02760426, -0.02760426, -0.02760426,\n",
       "        -0.02760426, -0.02760426, -0.02760426, -0.02760426, -0.02760426,\n",
       "        -0.02760426, -0.02760426, -0.02760426, -0.02760426, -0.02760426,\n",
       "        -0.02760426, -0.02760426, -0.02760426, -0.02760426, -0.02760426,\n",
       "        -0.02760426, -0.02760426, -0.02760426, -0.02760426, -0.02760426,\n",
       "        -0.02760426, -0.02760426, -0.02760426, -0.02760426, -0.02760426,\n",
       "        -0.02760426, -0.02760426, -0.02760426, -0.02760426, -0.02760426,\n",
       "        -0.02760426, -0.02760426, -0.02760426, -0.02760426, -0.02760426,\n",
       "        -0.02760426, -0.02760426, -0.02760426, -0.02760426, -0.02760426,\n",
       "         0.02760426,  0.02760426,  0.02760426,  0.02760426,  0.02760426,\n",
       "         0.02760426,  0.02760426,  0.02760426,  0.02760426,  0.02760426,\n",
       "         0.02760426,  0.02760426,  0.02760426,  0.02760426,  0.02760426,\n",
       "         0.02760426,  0.02760426,  0.02760426,  0.02760426,  0.02760426,\n",
       "         0.02760426,  0.02760426,  0.02760426,  0.02760426,  0.02760426,\n",
       "         0.02760426,  0.02760426,  0.02760426,  0.02760426,  0.02760426,\n",
       "         0.02760426,  0.02760426,  0.02760426,  0.02760426,  0.02760426,\n",
       "         0.02760426,  0.02760426,  0.02760426,  0.02760426,  0.02760426,\n",
       "         0.02760426,  0.02760426,  0.02760426,  0.02760426,  0.02760426,\n",
       "         0.02760426,  0.02760426,  0.02760426,  0.02760426,  0.02760426],\n",
       "       [-0.00477494, -0.00477494, -0.00477494, -0.00477494, -0.00477494,\n",
       "        -0.00477494, -0.00477494, -0.00477494, -0.00477494, -0.00477494,\n",
       "        -0.00477494, -0.00477494, -0.00477494, -0.00477494, -0.00477494,\n",
       "        -0.00477494, -0.00477494, -0.00477494, -0.00477494, -0.00477494,\n",
       "        -0.00477494, -0.00477494, -0.00477494, -0.00477494, -0.00477494,\n",
       "        -0.00477494, -0.00477494, -0.00477494, -0.00477494, -0.00477494,\n",
       "        -0.00477494, -0.00477494, -0.00477494, -0.00477494, -0.00477494,\n",
       "        -0.00477494, -0.00477494, -0.00477494, -0.00477494, -0.00477494,\n",
       "        -0.00477494, -0.00477494, -0.00477494, -0.00477494, -0.00477494,\n",
       "        -0.00477494, -0.00477494, -0.00477494, -0.00477494, -0.00477494,\n",
       "         0.00477494,  0.00477494,  0.00477494,  0.00477494,  0.00477494,\n",
       "         0.00477494,  0.00477494,  0.00477494,  0.00477494,  0.00477494,\n",
       "         0.00477494,  0.00477494,  0.00477494,  0.00477494,  0.00477494,\n",
       "         0.00477494,  0.00477494,  0.00477494,  0.00477494,  0.00477494,\n",
       "         0.00477494,  0.00477494,  0.00477494,  0.00477494,  0.00477494,\n",
       "         0.00477494,  0.00477494,  0.00477494,  0.00477494,  0.00477494,\n",
       "         0.00477494,  0.00477494,  0.00477494,  0.00477494,  0.00477494,\n",
       "         0.00477494,  0.00477494,  0.00477494,  0.00477494,  0.00477494,\n",
       "         0.00477494,  0.00477494,  0.00477494,  0.00477494,  0.00477494,\n",
       "         0.00477494,  0.00477494,  0.00477494,  0.00477494,  0.00477494]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = np.append(b,[0.04878128,0.01323187,0.02760426,0.00477494])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-296569c413ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# just to double check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.12047504\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.44156746\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m0.89309501\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2.965364\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.3427994\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# just to double check\n",
    "assert np.allclose(weight, np.array([0.12047504, -0.44156746, -0.89309501, 2.965364, 3.3427994]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (5,) and (100,5) not aligned: 5 (dim 0) != 100 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-63a5c7cca582>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# model accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-195af4b72417>\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(X, Y, weight)\u001b[0m\n\u001b[0;32m     11\u001b[0m     '''\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# implement your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0mcount_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-e68b33ee2d3d>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(w, b, X)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;34m'''Return predicted y of X'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-233f3c209df4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(w, b, X)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;34m'''Return y_hat'''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0my_hat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (5,) and (100,5) not aligned: 5 (dim 0) != 100 (dim 0)"
     ]
    }
   ],
   "source": [
    "# model accuracy\n",
    "accuracy(X, Y, weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) How low can you go?\n",
    "Do anything you want to get the best performance out of the training set. For once, let's overfit to your heart's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some fun code here and try to match this :)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weights:', weight)\n",
    "y = 1 / (1 + np.exp(-X @ weight))\n",
    "loss = -np.sum(Y * np.log(y) + (1 - Y) * np.log(1 - y)) / y.size\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy(X, Y, weight))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
