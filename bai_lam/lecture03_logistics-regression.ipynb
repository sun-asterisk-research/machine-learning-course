{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Logistics Regression\n",
    "Implement everywhere that has an ellipsis (`...`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "X, Y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only classify class 1 vs. class 2\n",
    "\n",
    "X = X[:, :]\n",
    "idx = (Y!=0)\n",
    "X = X[idx, :]\n",
    "Y = Y[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data normalization\n",
    "Remember: normalization is done per feature, not all at once. Also, remember that Y is [1, 2] instead of [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here. Don't forget the bias!\n",
    "X = (X - np.min(X)) / (np.max(X) - np.min(X))\n",
    "Y = (Y - np.min(Y)) / (np.max(Y) - np.min(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define classification model\n",
    "Create parameters here. Initialize with zeros. In case you forgot: $Y = \\sigma(X\\Theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forward Propagation:**\n",
    "$$Z = Xw + b$$\n",
    "$$\\hat{y} = \\sigma(Z) =\\sigma(Xw + b) $$\n",
    "$$J(w, b) = -\\frac{1}{m}\\sum_{i=1}^m{ \\Big( y^{(i)} log( \\hat{y}^{(i)}) + (1-y^{(i)}) log(1 - \\hat{y}^{(i)}) \\Big)} \\tag{5}$$\n",
    "\n",
    "**and Backward**\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial w} = \\frac{1}{m}X^T(\\hat{y}-y)\\tag{6}$$\n",
    "$$ \\frac{\\partial J}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^m (\\hat{y}^{(i)}-y^{(i)})\\tag{7}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = np.zeros(4)\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1 + np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward propagation\n",
    "def forward(w, b, X):\n",
    "    '''Return y_hat'''\n",
    "    Z = np.dot(X, w) + b\n",
    "    y_hat = sigmoid(Z)\n",
    "    return y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-4f4a8d6a8a74>, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-4f4a8d6a8a74>\"\u001b[1;36m, line \u001b[1;32m18\u001b[0m\n\u001b[1;33m    w = w -\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def accuracy(X, Y, w):\n",
    "    '''\n",
    "    Evaluate the model, represented by `weight`, with data (X, Y).\n",
    "    \n",
    "    Input:\n",
    "        X:      data features\n",
    "        Y:      data labels\n",
    "        weight: model weights\n",
    "    Ouput:\n",
    "        Model accuracy on input data.\n",
    "    '''\n",
    "    # implement your code here\n",
    "    \n",
    "    count_ = 0\n",
    "    for i in range(X.shape[1]):\n",
    "        z = np.dot(X,w)\n",
    "        y_hat = 1/(1 + np.exp(-z))\n",
    "        w = w - \n",
    "        if y_hat[i] < 0.5:\n",
    "            prediction = 0\n",
    "        else :\n",
    "            prediction = 1\n",
    "        if Y[i] == prediction:\n",
    "            count_ += 1\n",
    "    return count_ / X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "alpha = 1e-2\n",
    "# epochs\n",
    "epoch = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training process\n",
    "def train(X, Y, epoch, alpha,weight):\n",
    "    for i in range(epoch):\n",
    "        gd = (X.T @ (sigmoid(X @ weight) - Y)) / (Y.size)\n",
    "        w -= alpha * gd\n",
    "    return w\n",
    "w = train(X,Y,1000,1e-4,weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = np.append(b,[0.04878128,0.01323187,0.02760426,0.00477494])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to double check\n",
    "assert np.allclose(weight, np.array([0.12047504, -0.44156746, -0.89309501, 2.965364, 3.3427994]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model accuracy\n",
    "accuracy(X, Y, w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) How low can you go?\n",
    "Do anything you want to get the best performance out of the training set. For once, let's overfit to your heart's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do some fun code here and try to match this :)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weights:', weight)\n",
    "y = 1 / (1 + np.exp(-X @ weight))\n",
    "loss = -np.sum(Y * np.log(y) + (1 - Y) * np.log(1 - y)) / y.size\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', accuracy(X, Y, weight))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
